{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lib\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "# set cwd one up\n",
    "import os\n",
    "\n",
    "os.chdir(\"..\")\n",
    "path = \"data/hes/Hes1_example.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Library Imports\n",
    "from typing import Sequence\n",
    "\n",
    "# Third-Party Library Imports\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import gpflow\n",
    "import tensorflow_probability as tfp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Direct Namespace Imports\n",
    "from gpflow.kernels import Cosine, Matern12\n",
    "from gpflow.models import GPR\n",
    "from gpflow.optimizers import Scipy\n",
    "from tensorflow import Tensor\n",
    "\n",
    "# Internal Project Imports\n",
    "from gpcell.utils import load_data, detrend, background_noise\n",
    "from gpcell.backend import GPRConstructor, GPPrior, Numeric\n",
    "\n",
    "\n",
    "# TFP shortcuts\n",
    "tfd = tfp.distributions\n",
    "tfb = tfp.bijectors\n",
    "f64 = gpflow.utilities.to_default_float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------#\n",
    "# --- Load data, preprocess, and define priors --- #\n",
    "# -------------------------------------------------#\n",
    "\n",
    "# load data\n",
    "X_data_list, Y_data_list = load_data(path, \"Time (h)\", \"Cell\")\n",
    "X_background_list, Y_background_list = load_data(path, \"Time (h)\", \"Background\")\n",
    "num_cells = len(Y_data_list)\n",
    "print(f\"Loaded {num_cells} cells for analysis.\")\n",
    "\n",
    "# preprocess\n",
    "mean_noise, _ = background_noise(\n",
    "    X_background_list, Y_background_list, 7.0, verbose=True\n",
    ")\n",
    "noise_list = [mean_noise / np.std(y) for y in Y_data_list]\n",
    "\n",
    "Y_detrended_list, _ = detrend(X_data_list, Y_data_list, 7.0, verbose=True)\n",
    "\n",
    "\n",
    "# define priors\n",
    "def generate_ou_priors(noise: Numeric) -> GPPrior:\n",
    "    return {\n",
    "        \"kernel.lengthscales\": tfd.Uniform(low=f64(0.1), high=f64(2.0)),\n",
    "        \"kernel.variance\": tfd.Uniform(low=f64(0.1), high=f64(2.0)),\n",
    "        \"likelihood.variance\": noise**2,\n",
    "    }\n",
    "\n",
    "\n",
    "def generate_ouosc_priors(noise: Numeric) -> GPPrior:\n",
    "    return {\n",
    "        \"kernel.kernels[0].lengthscales.prior\": tfd.Uniform(\n",
    "            low=f64(0.1), high=f64(2.0)\n",
    "        ),\n",
    "        \"kernel.kernels[0].variance.prior\": tfd.Uniform(low=f64(0.1), high=f64(2.0)),\n",
    "        \"kernel.kernels[1].lengthscales.prior\": tfd.Uniform(\n",
    "            low=f64(0.1), high=f64(4.0)\n",
    "        ),\n",
    "        \"likelihood.variance\": noise**2,\n",
    "    }\n",
    "\n",
    "\n",
    "# define trainables\n",
    "ou_trainables = {\"likelihood.variance\": False}\n",
    "ouosc_trainables = {\n",
    "    \"likelihood.variance\": False,\n",
    "    (1, \"variance\"): False,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- MCMC Sampling Function ---\n",
    "def run_mcmc(model: GPR, num_samples: int = 1000, num_burnin_steps: int = 500):\n",
    "    # Note that here we need model.trainable_parameters, not trainable_variables - only parameters can have priors!\n",
    "    hmc_helper = gpflow.optimizers.SamplingHelper(\n",
    "        model.log_posterior_density, model.trainable_parameters\n",
    "    )\n",
    "\n",
    "    # define model\n",
    "    hmc = tfp.mcmc.HamiltonianMonteCarlo(\n",
    "        target_log_prob_fn=hmc_helper.target_log_prob_fn,\n",
    "        num_leapfrog_steps=10,\n",
    "        step_size=0.01,\n",
    "    )\n",
    "    adaptive_hmc = tfp.mcmc.SimpleStepSizeAdaptation(\n",
    "        hmc,\n",
    "        num_adaptation_steps=10,\n",
    "        target_accept_prob=f64(0.75),\n",
    "        adaptation_rate=0.1,\n",
    "    )\n",
    "\n",
    "    @tf.function(reduce_retracing=True)\n",
    "    def run_chain_fn():\n",
    "        return tfp.mcmc.sample_chain(\n",
    "            num_results=num_samples,\n",
    "            num_burnin_steps=num_burnin_steps,\n",
    "            current_state=hmc_helper.current_state,\n",
    "            kernel=adaptive_hmc,\n",
    "            trace_fn=lambda _, pkr: pkr.inner_results.is_accepted,\n",
    "        )\n",
    "\n",
    "    # run chain and extract samples\n",
    "    samples, _ = run_chain_fn()\n",
    "    parameter_samples = hmc_helper.convert_to_constrained_values(samples)\n",
    "\n",
    "    # map parameter names to indices\n",
    "    param_to_name = {\n",
    "        param: name for name, param in gpflow.utilities.parameter_dict(model).items()\n",
    "    }\n",
    "    name_to_index = {\n",
    "        param_to_name[param]: i for i, param in enumerate(model.trainable_parameters)\n",
    "    }\n",
    "\n",
    "    return samples, parameter_samples, param_to_name, name_to_index\n",
    "\n",
    "\n",
    "def plot_samples(\n",
    "    samples: Sequence[Tensor], parameters, y_axis_label: str, param_to_name: dict\n",
    "):\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    for val, param in zip(samples, parameters):\n",
    "        plt.plot(tf.squeeze(val), label=param_to_name[param])\n",
    "    plt.legend(bbox_to_anchor=(1.0, 1.0))\n",
    "    plt.xlabel(\"HMC iteration\")\n",
    "    plt.ylabel(y_axis_label)\n",
    "\n",
    "\n",
    "hyperparameters = [\n",
    "    \".kernel.kernels[0].lengthscales\",\n",
    "    \".kernel.kernels[0].variance\",\n",
    "    \".kernel.kernels[1].lengthscales\",\n",
    "]\n",
    "\n",
    "for idx, (X, Y_det) in enumerate(zip(X_data_list, Y_detrended_list)):\n",
    "    print(f\"\\nProcessing cell {idx + 1}/{num_cells} with {X.shape[0]} data points...\")\n",
    "    noise = noise_list[idx]\n",
    "\n",
    "    # Build the GP model on the detrended data\n",
    "    ouosc_priors = generate_ouosc_priors(noise)\n",
    "    model_constructor = GPRConstructor(\n",
    "        [Matern12, Cosine],\n",
    "        lambda noise=noise: generate_ouosc_priors(noise),\n",
    "        ouosc_trainables,\n",
    "    )\n",
    "    model = model_constructor(X, Y_det, MCMC=True)\n",
    "\n",
    "    optimizer = Scipy()\n",
    "    optimizer.minimize(\n",
    "        model.training_loss,\n",
    "        model.trainable_variables,  # type: ignore\n",
    "        options=dict(maxiter=100),\n",
    "    )\n",
    "    gpflow.utilities.print_summary(model, fmt=\"notebook\")\n",
    "\n",
    "    # Run MCMC sampling\n",
    "    samples, parameter_samples, param_to_name, name_to_index = run_mcmc(\n",
    "        model, num_samples=1500, num_burnin_steps=500\n",
    "    )\n",
    "\n",
    "    # plot samples\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    for param_name in hyperparameters:\n",
    "        plt.plot(parameter_samples[name_to_index[param_name]], label=param_name)\n",
    "    plt.legend(bbox_to_anchor=(1.0, 1.0))\n",
    "    plt.xlabel(\"HMC iteration\")\n",
    "    plt.ylabel(\"hyperparameter value\")\n",
    "\n",
    "    gpflow.utilities.print_summary(model, fmt=\"notebook\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
