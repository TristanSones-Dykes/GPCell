# Methods

## Gaussian Processes

### Introduction

A Gaussian Process (GP) is a powerful, non-parametric Bayesian approach to modeling distributions over functions. In regression tasks, GPs provide a flexible framework that not only predicts mean function values but also quantifies uncertainty, making them particularly suitable for modeling noisy and complex biological time-series data, such as gene expression profiles.

Formally, a GP is defined as a collection of random variables, any finite number of which have a joint Gaussian distribution. A GP is fully specified by its mean function $m(\mathbf x)$ and covariance function (kernel) $k(\mathbf x, \mathbf x^\prime)$:

$$
f(\mathbf x) \thicksim GP(m(\mathbf x), k(\mathbf x, \mathbf x^\prime))
$$

For practical applications, and in our case, the mean function is often assumed to be zero ($m(\mathbf x) = 0$) as we can remove trends from our data and then focus on the kernel component which differentiates our models.

### Regression

Given a set of training (for us, time) inputs $\mathbf X = {\mathbf x_1, ..., \mathbf x_n}$ and observations $\mathbf Y = {\mathbf y_1, ..., \mathbf y_n}$; each observation is modelled as $\mathbf y_i = f(\mathbf x_i) + \epsilon_i$ with $\epsilon_i \sim N(0, \sigma_n^2)$ Gaussian noise. The objective is to predict the value $f(\mathbf x_*)$ at new input $\mathbf x_*$.

The joint distribution of the observed values and function at $\mathbf x_*$ is given by:

$$
\begin{align}
\begin{bmatrix}
\mathbf y \\
f_*
\end{bmatrix}
&\sim 
\mathcal N\bigl(
\begin{bmatrix}
0 \\ 0
\end{bmatrix}
,
\begin{bmatrix}
\mathbf K(\mathbf X, \mathbf X) + \sigma_n^2 I & \mathbf K(\mathbf X, \mathbf x_*) \\
\mathbf K(\mathbf x_*, \mathbf X) & \mathbf K(\mathbf x_*, \mathbf x_*)
\end{bmatrix}
\bigr)
\end{align}
$$

Where $\mathbf K(\mathbf X, \mathbf X)$ is the covariance matrix computed over the training inputs and $\mathbf K(\mathbf X, \mathbf x_*)$ is covariance vector between the training inputs and the new input.

The predictive distribution for $f_*$ is then Gaussian with known mean and variance.

### Kernels

The choice of kernel (or covariance function) $k(\mathbf x, \mathbf x^\prime)$ is crucial as it determines the behaviour of the model.

## GPCell Introduction

Utilizing the GPflow library, which is based on TensorFlow, it provides a user-friendly interface for researchers, with an OscillatorDetector class specifically designed for this use-case. It also has unit tests to verify correctness, a strong type system to aid development and upkeep, as well as a suite of abstracted utility functions that automate the model fitting process through a multiprocessing pipeline increasing fitting speed.

## Software Architecture

Class diagram of your library structure (OscillatorDetector, GaussianProcess, GPRConstructor, utility modules)

Detailed explanation of key classes and methods (GaussianProcess, OscillatorDetector, utility functions like fit_processes)

## Optimisations and Computational Strategies

Joblib for parallel processing​

NumPy and Numba for just-in-time compilation

MCMC methods implemented using TensorFlow Probability​gaussian_process​gpr

Detailed computational steps (include diagrams or pseudocode)

## Extensibility and Modularity

Explain library extensibility (custom kernels, different inference techniques, user-defined prior distributions)​priors

Small illustrative code snippets demonstrating ease of extending or adapting methods