# Results

## Reproducing Previous Results

A key plot in @phillips_identifying_2017 is the ROC curve comparing the GP method to the Lomb-Scargle method. It is reproduced below, with added AUC values for both methods.

![Example simulated traces and model ROC curves, factored by simulated noise level $\sigma^2$ and trace length (time)](ROC_plot.png){width="65%"}

This shows that GPCell fits the same quality models as the MATLAB implementation, on MATLAB generated data. The ROC curves don't have margins on the original plot, adding them makes spotting discrepancies between the models easier.

The added AUC values give a lot of information; despite the $\sigma^2 = 0.5$ ROC for the GP method looking far worse than the others, the AUC shows us it is, quantitatively, not as dissimilar from the others as it looks.

## Performance Improvements

There were two key areas of performance improvement, in fitting models and in simulating data. Some of the improvement was just from switching to MATLAB, but the majority, especially on large datasets, comes from deliberate computational improvements.

### Model Fitting

Using `Joblib`, GPCell is able to fit distribute the job of fitting a set of replicate models to a trace as processes ran on separate cores.\
Shown below are the results of fitting the core BIC pipeline (OU and OUosc models) to homogeneous (matrix shaped), and non-homogeneous (jagged) datasets. This makes a difference as, through `Joblib`, GPCell is programmed to take advantage of NumPy's `memmap` when possible. It writes the square dataset to a temporary file and provides each process with a read-only reference, allowing concurrent access and reducing memory overhead.

```{r, echo=FALSE, message=FALSE}
#| fig-cap: Time taken to fit processes, split by data source and backend

library(tidyverse)

# create dataframe of results
source <- c("homogenous", "homogenous", "homogenous", "homogenous", "nonhomog", "nonhomog", "nonhomog")
cells_fit <- c(1000, 1000, 100, 100, 12, 12, 12)
method <- c("base", "joblib", "base", "joblib", "MATLAB", "base", "joblib")
time <- c(3000, 408, 301.39, 51.21, 44.41, 36.09, 12.0)

results <- data.frame(source, cells_fit, method, time)
results$source <- factor(results$source, levels = c("homogenous", "nonhomog"))
results$method <- factor(results$method, levels = c("base", "joblib", "MATLAB"))
results$time <- as.numeric(results$time)

# plot results
ggplot(results, aes(x = cells_fit, y = time, color = method)) +
  geom_point(aes(shape = source)) +
  geom_line() +
  scale_y_log10() +
  scale_x_log10() +
  labs(
    x = "Number of cells (log)",
    y = "Time taken to fit models (log s)",
    color = "Method"
  ) +
  theme_minimal()
```

This shows the stark difference between fitting models in parallel and in sequence as the number of cells increases. The larger numbers of cells are fitted as homogeneous alone because it is more stable due to memory usage.

### Data Generation

In the original MATLAB implementation, parallel processing is only available with external tooling, and does not take full advantage of vector processing.\
Below is a table comparing the time taken to simulate cells (needed for model evaluation and tuning) at the different levels of optimisation.

```{r, echo=FALSE}
impl_names <- c(
  "Python, parallel and njit",
  "Python, parallel",
  "Python",
  "MATLAB"
)

times <- c(
  "58.64",
  "315.23",
  "3722.16",
  "Approx 1.5 hours"
)

knitr::kable(data.frame(Implementation = impl_names, `Time (s)` = times), caption = "Average data simulation times")
```

Each optimisation decreases the time taken by an order of magnitude, the final optimisation only being possible to due compiling the simulation function (which requires it only be written in NumPy with limited base Python).

These optimisations help in two ways; first by increasing the number of experiments that can be ran and reducing the impact on servers, but also by lowering the computational barrier to use and contribute to the library effectively.

## MCMC Model

Example MCMC fits (trace plots, parameter distributions).

Show how it works on the data, performance of classification.

Discuss implications and accuracy improvements from MCMC inference.