{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "124c2c30",
   "metadata": {},
   "source": [
    "# A tutorial for identifying stochastic oscillations in single-cell live imaging time series using GPflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3e7de2",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71061a10",
   "metadata": {},
   "source": [
    "This is a tutorial to accompany our paper: \n",
    "\n",
    "Phillips NE, Manning C, Papalopulu N & Rattray M (2017) Identifying stochastic oscillations in single cell live imaging time series using Gaussian processes. PLoS Comput Biol: 1â€“30 (https://doi.org/10.1371/journal.pcbi.1005479)\n",
    "\n",
    "The aim of the method is to classify whether a single-cell gene expression time series is periodic. The original code used MATLAB, but this tutorial will show an alternative implementation using GPflow that provides a number of advantages. Here we will see a minimal implementation of the method, but it can easily be customised and extended for specific needs.\n",
    "\n",
    "Contents:\n",
    "\n",
    "1. Why GPflow?\n",
    "2. The challenges of identifying oscillations in single-cell time series\n",
    "3. Simulating the OU and OUosc models\n",
    "4. An overview of the full analysis pipeline\n",
    "5. An example analysis\n",
    "6. Final thoughts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066c7d1c",
   "metadata": {},
   "source": [
    "## Why GPflow?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc1545f",
   "metadata": {},
   "source": [
    "GPflow (https://www.gpflow.org) is a package for implementing Gaussian process models using Python and TensorFlow. The cool thing about using GPflow is that it offers many functionalities that could help customise the method for specific biological questions. In this tutorial we will focus on a basic reimplementation of our published method, but here are just a few ways that GPflow could in principle be used to extend the model:\n",
    "\n",
    "1. The method assumes that gene expression is either oscillatory or non-oscillatory for the entire duration of the time series. During development, however, stem cells may make dynamic transitions from oscillatory to non-oscillatory gene expression as they differentiate into more specialised cells. In the Discussion we suggested that it would be interesting to use a change-point model that could somehow account for this. A change-point kernel is implemented in GPflow (https://gpflow.github.io/GPflow/develop/notebooks/advanced/changepoints.html).\n",
    "\n",
    "2. Similarly, the model assumes that the variance of the gene expression dynamics remains constant over time, but this assumption could be relaxed by using a heteroskedastic likelihood (https://gpflow.github.io/GPflow/develop/notebooks/advanced/heteroskedastic.html).\n",
    "\n",
    "3. For our particular dataset, the time series were short enough such that we didn't need any tools to accelerate inference. When the inference becomes too time-consuming for longer time series, GPflow offers techniques such Stochastic Variational Gaussian Process (SVGP) that could help speed things up (https://gpflow.github.io/GPflow/develop/notebooks/advanced/gps_for_big_data.html).\n",
    "\n",
    "4. We used maximum likelihood to fit our models, and so for each cell we have a single point estimate of parameter values. With GPflow it would be possible to use Hamiltonian Monte Carlo (HMC) to also have uncertainty on these parameters (https://gpflow.github.io/GPflow/develop/notebooks/advanced/mcmc.html), which could be used downstream for e.g. testing for differences in dynamics between two different cells. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e94e70",
   "metadata": {},
   "source": [
    "## The challenges of identififying oscillations in single-cell time series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9351af8f",
   "metadata": {},
   "source": [
    "As mentioned in the introduction of the paper, there are many interesting biological systems that exhibit oscillatory dynamics, such as circadian rhythms, the cell cycle, NF-KB oscillations in inflammation and p53 oscillations in response to DNA damage. \n",
    "\n",
    "We can now use live-cell imaging with fluorescent or bioluminescent markers to track gene expression in single cells, but for practical, technical and biological reasons, these time series are often short and noisy.\n",
    "\n",
    "A common question is often posed: is the time series *really* oscillating?\n",
    "\n",
    "Let's use a simple example to illustrate why this is a difficult question to answer.\n",
    "\n",
    "Imagine that I give you the following sequence of coin flips: heads, tails, heads, tails (HTHT). And now imagine that I ask you whether you think the observed sequence was the outcome of an oscillatory process. On one hand, we do indeed observe a rhythmic pattern in the data. On the other hand, the sequence is pretty short and we don't have a lot of data to make a decision with. Perhaps this sequence was just the outcome of a series of completely random coin flips, where the periodicity just occurred by chance?\n",
    "\n",
    "There's a further complication with biological systems. Unlike e.g. planetary motion, where we expect the period of oscillations to be extremely regular, in single cells the oscillations are often noisy with an irregular peak-to-peak period. One possible source of this stochasticity is the fact that intra-cellular oscillations are controlled by reactions involving a low number of interacting molecules. To reuse the analogy of coin-flipping, this irregularity in the period means that oscillatory gene expression in single cells is more like: HHTTTHHHTTHHTTTT.\n",
    "\n",
    "Conceptually, the most important aspect of the method to understand is that for each cell we will propose two different models of the underlying dynamics: 1) a non-oscillatory model that generates noisy fluctuations with a given general timescale but without a specific period (the OU model), 2) an oscillatory model where the period of the oscillations are not necessarily perfect (the OUosc model).\n",
    "\n",
    "The best way of gaining an intuition for the method is by first simulating the non-oscillatory OU and the oscillatory OUosc models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c382193",
   "metadata": {},
   "source": [
    "## Setting up the environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236f1949",
   "metadata": {},
   "source": [
    "The right packages (and versions) are needed for this tutorial to run, and a conda environment is included for this purpose.\n",
    "\n",
    "If you don't already have Anaconda, you can download it [here](https://www.anaconda.com/products/distribution).\n",
    "\n",
    "We'll use the GPosc.yml file included in the Github folder to download the right package versions. Open a terminal and first change directory to where you've downloaded the .yml file. Then create a new environment in the terminal using (see guide for managing conda environments [here](https://docs.conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html#creating-an-environment-from-an-environment-yml-file) ):\n",
    "\n",
    "conda env create -f GPosc.yml\n",
    "\n",
    "And activate it with:\n",
    "\n",
    "conda activate GPosc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b82a8db",
   "metadata": {},
   "source": [
    "## Simulating the OU and OUosc models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b23917",
   "metadata": {},
   "source": [
    "The aperiodic OU model and the periodic (formally quasi-periodic) OUosc model are derived from a simplified model of intracellular dynamics, and the details of the two models are outlined in the original article. \n",
    "\n",
    "From a practical perspective, the OU model describes a noisy, aperiodic dynamical system controlled by two parameters: one parameter controls the rapidity of the fluctuations, and the second parameter controls the magnitude (or the variance) of the fluctuations.\n",
    "\n",
    "Let's now simulate the model within GPflow. We first need to define the timescale (in units of hours), where a short timescale will lead to fast fluctuations. We then define the variance of the process, where a high variance will lead to large magnitude fluctuations.\n",
    "\n",
    "I recommend playing with the timescale and variance parameters to get an intuition for how they affect the resulting dynamics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e2e87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gpflow\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "from gpflow.utilities import print_summary, set_trainable, to_default_float\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "timescale = 2.0\n",
    "variance = 1.0\n",
    "\n",
    "X = np.linspace(0, 25, 100).reshape(-1, 1)\n",
    "k_ou = gpflow.kernels.Matern12(lengthscales=timescale, variance=variance)\n",
    "\n",
    "Y = np.random.multivariate_normal(np.zeros(len(X)), k_ou(X)).T\n",
    "\n",
    "plt.plot(X, Y)\n",
    "plt.xlabel(\"Time (h)\")\n",
    "plt.ylabel(\"Normalised gene expression\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd4bf9c",
   "metadata": {},
   "source": [
    "The time series shows local peaks and troughs even though we generated it from a non-oscillatory process. This shows why heuristic methods based on finding peaks can't necessarily demonstrate that a time series is oscillating.\n",
    "\n",
    "We can also simulate the periodic OUosc model. Like the OU model, the OUosc model also has a parameter that describes the rapidity of fluctuations and another that describes the variance. There is also a third variable that fixes the period the fluctuations. Once again, I recommend playing with these parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97490eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "timescale = 2.0\n",
    "variance = 1.0\n",
    "period = 3.0\n",
    "\n",
    "X = np.linspace(0, 25, 100).reshape(-1, 1)\n",
    "k_ou_osc = gpflow.kernels.Matern12(\n",
    "    lengthscales=timescale, variance=variance\n",
    ") * gpflow.kernels.Cosine(lengthscales=period)\n",
    "\n",
    "Y = np.random.multivariate_normal(np.zeros(len(X)), k_ou_osc(X)).T\n",
    "\n",
    "plt.plot(X, Y)\n",
    "plt.xlabel(\"Time (h)\")\n",
    "plt.ylabel(\"Normalised gene expression\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ff9c5e",
   "metadata": {},
   "source": [
    "With the OUosc model we see noisy oscillations in the time series, such that the peak-to-peak period is irregular.\n",
    "\n",
    "When we simulate the model, we provide the inputs to the model (i.e. the parameters) and we generate a stochastic time series as an output. In the analysis pipeline we effectively go in the other direction: we start with the time series (i.e. the data) and we find the parameters that \"best describe\" our data. We do this by maximising the log-likelihood of the data for a given set of parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65083c74",
   "metadata": {},
   "source": [
    "## An overview of the full analysis pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e42a81",
   "metadata": {},
   "source": [
    "In addition to the changes in gene expression that we see on fairly rapid timescales (e.g. 1-3 hours), we sometimes observe large, long timescale trends within the data. These trends may result from underlying biological processes or may simply result from microscopy artifacts of varying sources. The method involves a detrending step to remove these trends. The methods requires a characteristic timescale to remove trends, and we loosely recommend about 3X the expected period.\n",
    "\n",
    "In addition to the long timescale trends, measuring gene expression using microscopy is not 100% accurate and there are errors associated with each measurement. In our analysis pipeline we model this experimental noise as Gaussian \"white\" noise, meaning that the measurement error is assumed to follow a normal distribution and that the errors are assumed to be independent at each time point. \n",
    "\n",
    "The Gaussian (i.e. normal) distribution describing the experimental error has a parameter that controls the variance. In the paper we estimated this experimental noise variance by creating four background regions that had the same area as a typical cell but were empty (i.e. they contained no cells). Using these four background regions, we then remove any long timescale trend while simultaneously estimating the experimental noise.\n",
    "\n",
    "If background data is missing or otherwise unavailable, this error term can in principle be estimated from the data alongside other parameters of the model. One could, for example, add an experimental noise variance as a global parameter that's shared across cells, but in practice this complicates the analysis as it would no longer be possible to learn the parameters for each cell within a simple for loop (as is currently the case).\n",
    "\n",
    "Here is a summary of the analysis pipeline:\n",
    "\n",
    "Input: cells to be analysed, background cells (e.g. 4 regions).\n",
    "\n",
    "1. Estimate experimental noise using background regions\n",
    "2. Remove long timescale trend for each cell\n",
    "3. Fit OU and OUosc model to each cell and calculate the log likelihood ratio (LLR) of the two models\n",
    "4. Create a dataset of synthetic, non-oscillatory cells using the OU model. Calculate the LLR for each cell.\n",
    "5. Using the LLRs of the observed cells and the synthetic, non-oscillatory cells, calculate a q-value for each observed cell.\n",
    "6. Accept cells as oscillating if their associated q-value is lower than a cut-off (e.g. 0.05)\n",
    "\n",
    "Output: a q-value for each cell that can be used to classify the cell as oscillatory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4648d4d7",
   "metadata": {},
   "source": [
    "## An example analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7372226",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f37117f",
   "metadata": {},
   "source": [
    "We first load the data we wish to analyse. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "888a0c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_name):\n",
    "    df = pd.read_csv(file_name).fillna(0)\n",
    "    data_cols = [col for col in df if col.startswith(\"Cell\")]\n",
    "    bckgd_cols = [col for col in df if col.startswith(\"Background\")]\n",
    "    time = df[\"Time (h)\"].values[:, None]\n",
    "\n",
    "    bckgd = df[bckgd_cols].values\n",
    "    M = np.shape(bckgd)[1]\n",
    "\n",
    "    bckgd_length = np.zeros(M, dtype=np.int32)\n",
    "\n",
    "    for i in range(M):\n",
    "        bckgd_curr = bckgd[:, i]\n",
    "        bckgd_length[i] = np.max(np.nonzero(bckgd_curr))\n",
    "\n",
    "    y_all = df[data_cols].values\n",
    "\n",
    "    N = np.shape(y_all)[1]\n",
    "\n",
    "    y_all = df[data_cols].values\n",
    "    np.max(np.nonzero(y_all))\n",
    "\n",
    "    y_length = np.zeros(N, dtype=np.int32)\n",
    "\n",
    "    for i in range(N):\n",
    "        y_curr = y_all[:, i]\n",
    "        y_length[i] = np.max(np.nonzero(y_curr))\n",
    "\n",
    "    return time, bckgd, bckgd_length, M, y_all, y_length, N\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "os.chdir(\"../data/hes\")\n",
    "file_name = \"Hes1_example.csv\"  # add your file name here\n",
    "time, bckgd, bckgd_length, M, y_all, y_length, N = load_data(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3881f09",
   "metadata": {},
   "source": [
    "The \"load_data\" function accepts data with a specific format, which you can check using the provided example .csv file. There are three requirements:\n",
    "\n",
    "- A column with the time of each measurement (units in hours). Column name: Time (h)\n",
    "- Empty background regions that have the same area as a typical cell. The column name of each background region starts with: Background. There are four background regions in the example.\n",
    "- Cells to be analysed, where the column name of each cell begins with: Cell\n",
    "\n",
    "The load_data function returns seven outputs:\n",
    "1. time - the time in hours\n",
    "2. bckgd - the background regions\n",
    "3. bckgd_length - this denotes the length of each background trace (which can be different)\n",
    "4. M - the total number of background regions\n",
    "5. y_all - the time series of the cells to be analysed\n",
    "6. y_length - the length of each cell trace\n",
    "7. N - the total number of cells to be analysed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d01e2d",
   "metadata": {},
   "source": [
    "## Estimating experimental noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af41b646",
   "metadata": {},
   "source": [
    "We then estimate the experimental noise. Using the background regions, we remove any long timescale trend while simultaneously estimating the experimental noise. The generated graphs show the estimated trend (black line) and 2X standard deviation (red lines)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d208bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimised_background_model(X, Y):\n",
    "    k = gpflow.kernels.SquaredExponential()\n",
    "    m = gpflow.models.GPR(data=(X, Y), kernel=k, mean_function=None)\n",
    "    m.kernel.lengthscales = gpflow.Parameter(\n",
    "        to_default_float(7.1),\n",
    "        transform=tfp.bijectors.Softplus(low=to_default_float(7.0)),\n",
    "    )\n",
    "    opt = gpflow.optimizers.Scipy()\n",
    "    opt_logs = opt.minimize(\n",
    "        m.training_loss, m.trainable_variables, options=dict(maxiter=100)\n",
    "    )\n",
    "\n",
    "    return m\n",
    "\n",
    "\n",
    "std_vec = np.zeros(M)\n",
    "\n",
    "fig = plt.figure(figsize=(15 / 2.54, 15 / 2.54))\n",
    "\n",
    "for i in range(M):\n",
    "    X = time[: bckgd_length[i]]\n",
    "    Y = bckgd[: bckgd_length[i], i, None]\n",
    "    Y = Y - np.mean(Y)\n",
    "\n",
    "    m = optimised_background_model(X, Y)\n",
    "\n",
    "    mean, var = m.predict_y(X)\n",
    "\n",
    "    plt.subplot(2, 2, i + 1)\n",
    "    plt.plot(X, Y)\n",
    "    plt.plot(X, mean, \"k\")\n",
    "    plt.plot(X, mean + 2 * var**0.5, \"r\")\n",
    "    plt.plot(X, mean - 2 * var**0.5, \"r\")\n",
    "\n",
    "    if i % 2 == 0:\n",
    "        plt.ylabel(\"Luminescence (AU)\")\n",
    "    if i >= 2:\n",
    "        plt.xlabel(\"Time (h)\")\n",
    "\n",
    "    std_vec[i] = m.likelihood.variance**0.5\n",
    "\n",
    "plt.tight_layout()\n",
    "std = np.mean(\n",
    "    std_vec\n",
    ")  # the estimated standard deviation of the experimental noise, averaged over all background traces\n",
    "\n",
    "print(std)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43538db5",
   "metadata": {},
   "source": [
    "## Fitting the OU and OUosc models to single-cell time series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0680e8b",
   "metadata": {},
   "source": [
    "Next, we will iterate over all cells to be analysed using a for loop. For each cell we will first remove any long term trend, fit the OU and OUosc models and calculate the log likelihood ratio (LLR) of the two models. We will also store the parameters of the fitted models, as we need the fitted parameters to simulate synthetic non-oscillatory cells from the OU model in the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "861b0e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.mlab import detrend\n",
    "\n",
    "\n",
    "def detrend_cell(X, Y, detrend_lengthscale):\n",
    "    k_trend = gpflow.kernels.SquaredExponential()\n",
    "    m = gpflow.models.GPR(data=(X, Y), kernel=k_trend, mean_function=None)\n",
    "\n",
    "    m.kernel.lengthscales = gpflow.Parameter(\n",
    "        to_default_float(detrend_lengthscale + 0.1),\n",
    "        transform=tfp.bijectors.Softplus(low=to_default_float(detrend_lengthscale)),\n",
    "    )\n",
    "\n",
    "    opt = gpflow.optimizers.Scipy()\n",
    "    opt_logs = opt.minimize(\n",
    "        m.training_loss, m.trainable_variables, options=dict(maxiter=100)\n",
    "    )\n",
    "\n",
    "    mean, var = m.predict_f(X)\n",
    "\n",
    "    Y_detrended = Y - mean\n",
    "    Y_detrended = Y_detrended - np.mean(Y_detrended)\n",
    "\n",
    "    return k_trend, mean, var, Y_detrended\n",
    "\n",
    "\n",
    "def fit_models(X, Y, noise, K):\n",
    "    OU_LL_list, OU_param_list, OUosc_LL_list, OUosc_param_list = [[] for _ in range(4)]\n",
    "\n",
    "    for k in range(K):\n",
    "        k_ou = gpflow.kernels.Matern12()\n",
    "\n",
    "        m = gpflow.models.GPR(data=(X, Y), kernel=k_ou, mean_function=None)\n",
    "        m.kernel.variance.assign(np.random.uniform(0.1, 2.0))\n",
    "        m.kernel.lengthscales.assign(np.random.uniform(0.1, 2.0))\n",
    "        m.likelihood.variance.assign(noise**2)\n",
    "        gpflow.set_trainable(m.likelihood.variance, False)\n",
    "\n",
    "        # gpflow.utilities.print_summary(m)\n",
    "        opt = gpflow.optimizers.Scipy()\n",
    "        opt_logs = opt.minimize(\n",
    "            m.training_loss, m.trainable_variables, options=dict(maxiter=100)\n",
    "        )\n",
    "\n",
    "        nlmlOU = m.log_posterior_density()\n",
    "\n",
    "        OU_LL = nlmlOU\n",
    "        OU_LL_list.append(OU_LL)\n",
    "        OU_param_list.append(k_ou)\n",
    "\n",
    "        k_ou_osc = gpflow.kernels.Matern12() * gpflow.kernels.Cosine()\n",
    "\n",
    "        m = gpflow.models.GPR(data=(X, Y), kernel=k_ou_osc, mean_function=None)\n",
    "        m.likelihood.variance.assign(noise**2)\n",
    "        gpflow.set_trainable(m.likelihood.variance, False)\n",
    "        gpflow.set_trainable(m.kernel.kernels[1].variance, False)\n",
    "        m.kernel.kernels[0].variance.assign(np.random.uniform(0.1, 2.0))\n",
    "        m.kernel.kernels[0].lengthscales.assign(np.random.uniform(0.1, 2.0))\n",
    "        m.kernel.kernels[1].lengthscales.assign(np.random.uniform(0.1, 4.0))\n",
    "\n",
    "        # print_summary(m)\n",
    "        opt = gpflow.optimizers.Scipy()\n",
    "        opt_logs = opt.minimize(\n",
    "            m.training_loss, m.trainable_variables, options=dict(maxiter=100)\n",
    "        )\n",
    "\n",
    "        # print_summary(m)\n",
    "        # print(\"---\")\n",
    "\n",
    "        nlmlOSC = m.log_posterior_density()  # opt_logs.fun\n",
    "\n",
    "        OU_osc_LL = nlmlOSC\n",
    "        OUosc_LL_list.append(OU_osc_LL)\n",
    "        OUosc_param_list.append(k_ou_osc)\n",
    "\n",
    "    LLR = 100 * 2 * (np.max(OUosc_LL_list) - np.max(OU_LL_list)) / len(Y)\n",
    "    BIC_OUosc = -2 * np.max(OUosc_LL_list) + 3 * np.log(len(Y))\n",
    "    BIC_OU = -2 * np.max(OU_LL_list) + 2 * np.log(len(Y))\n",
    "    BICdiff = BIC_OU - BIC_OUosc\n",
    "\n",
    "    print(np.max(OU_LL_list), np.max(OUosc_LL_list))\n",
    "    print(len(Y))\n",
    "\n",
    "    k_ou = OU_param_list[np.argmax(OU_LL_list)]\n",
    "    k_ou_osc = OUosc_param_list[np.argmax(OUosc_LL_list)]\n",
    "\n",
    "    cov_ou_osc = OUosc_param_list[0](X).numpy()[0, :]\n",
    "    peaks, _ = find_peaks(cov_ou_osc, height=0)\n",
    "\n",
    "    if len(peaks) != 0:\n",
    "        period = X[peaks[0]]\n",
    "    else:\n",
    "        period = 0\n",
    "\n",
    "    return LLR, BICdiff, k_ou, k_ou_osc, period\n",
    "\n",
    "\n",
    "def plot_model_fits(\n",
    "    cell, x_curr, y_curr, mean_trend, noise, LLR, k_trend, k_ou, k_ou_osc, period\n",
    "):\n",
    "    fig = plt.figure(figsize=(12 / 2.54, 8 / 2.54))\n",
    "    plt.plot(x_curr, y_curr)\n",
    "    plt.plot(x_curr, mean_trend, \"k--\", alpha=0.5)\n",
    "    plt.xlabel(\"Time (hours)\")\n",
    "    plt.ylabel(\"Luminescence (normalised) (AU)\")\n",
    "    plt.title(\"Cell \" + str(cell) + \" , LLR = \" + f\"{LLR:.1f}\")\n",
    "\n",
    "\n",
    "(\n",
    "    noise_list,\n",
    "    detrend_param_list,\n",
    "    LLR_list,\n",
    "    BICdiff_list,\n",
    "    OU_param_list,\n",
    "    OUosc_param_list,\n",
    "    period_list,\n",
    ") = [[] for _ in range(7)]\n",
    "\n",
    "detrended_list = []\n",
    "mean_list = []\n",
    "\n",
    "for cell in range(N):\n",
    "    x_curr = time[: y_length[cell]]\n",
    "    y_curr = y_all[: y_length[cell], cell, None]\n",
    "    noise = std / np.std(y_curr)\n",
    "    y_curr = (y_curr - np.mean(y_curr)) / np.std(y_curr)\n",
    "\n",
    "    k_trend, mean_trend, var_trend, Y_detrended = detrend_cell(x_curr, y_curr, 7.0)\n",
    "    detrended_list.append(Y_detrended)\n",
    "    mean_list.append(mean_trend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2d97c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cell in range(N):\n",
    "    x_curr = time[: y_length[cell]]\n",
    "    Y_detrended = detrended_list[cell]\n",
    "\n",
    "    print(\"OU/OUosc\")\n",
    "    LLR, BICdiff, k_ou, k_ou_osc, period = fit_models(x_curr, Y_detrended, noise, 10)\n",
    "\n",
    "    noise_list.append(noise)\n",
    "    detrend_param_list.append(k_trend)\n",
    "    LLR_list.append(LLR)\n",
    "    BICdiff_list.append(BICdiff)\n",
    "    OU_param_list.append(k_ou)\n",
    "    OUosc_param_list.append(k_ou_osc)\n",
    "    period_list.append(period)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4894bbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(noise_list)\n",
    "\n",
    "for params in detrend_param_list:\n",
    "    print(params.parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f804713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot all detrended traces with original data\n",
    "fig = plt.figure(figsize=(15 / 2.54 * 3, 15 / 2.54 * 3))\n",
    "\n",
    "for i in range(N):\n",
    "    x_curr = time[: y_length[i]]\n",
    "    y_curr = y_all[: y_length[i], i, None]\n",
    "    mean_trend = mean_list[i]\n",
    "\n",
    "    y_plot = (y_curr - np.mean(y_curr)) / np.std(y_curr)\n",
    "\n",
    "    plt.subplot(4, 4, i + 1)\n",
    "    plt.plot(x_curr, detrended_list[i])\n",
    "    plt.plot(x_curr, y_plot)\n",
    "    plt.plot(x_curr, mean_trend, \"k--\", alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bbc805f",
   "metadata": {},
   "source": [
    "There are seven outputs of this section:\n",
    "\n",
    "1. noise_list - each cell is normalised by dividing by the standard deviation. This list records the normalisation constant\n",
    "2. detrend_param_list - records the parameters of the model used for detrending the cell\n",
    "3. LLR_list - the log-likelihood ratio between OUosc and OU model for each cell\n",
    "4. BICdiff_list - the difference in the Bayesian information criterion (BIC) between the models\n",
    "5. OU_param_list - the fitted parameters of the OU model for each cell\n",
    "6. OUosc_param_list - the fitted parameters of the OUosc model for each cell\n",
    "7. period_list - the oscillatory period of the OUosc model. Note that even if a period is estimated, the cell may not pass the periodicity test performed later"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c5e4d7",
   "metadata": {},
   "source": [
    "## Rough estimation of number of oscillating cells using BIC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60983a07",
   "metadata": {},
   "source": [
    "We now have a list of LLRs for the cells. In the full method we will calculate an LLR_list for synthetic, non-oscillating cells, but this can be quite time consuming.\n",
    "\n",
    "A quicker method is to use the difference in the BIC between the two models [(BIC wiki page)](https://en.wikipedia.org/wiki/Bayesian_information_criterion). A cut-off on the BICdiff can then be used to accept the oscillatory model, and we can use a BICdiff>3 to consider the cell as oscillating ([Kass  & Raftery](https://doi.org/10.2307/2291091))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732a0fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12 / 2.54, 6 / 2.54))\n",
    "\n",
    "cutoff = 3\n",
    "print(\n",
    "    \"Number of cells counted as oscillatory (BIC method): {0}/{1}\".format(\n",
    "        sum(np.array(BICdiff_list) > cutoff), len(BICdiff_list)\n",
    "    )\n",
    ")\n",
    "\n",
    "plt.hist(BICdiff_list, bins=np.linspace(-20, 20, 40))\n",
    "plt.plot([cutoff, cutoff], [0, 2], \"r--\")\n",
    "plt.xlabel(\"LLR\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"LLRs of experimental cells\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ff19d5",
   "metadata": {},
   "source": [
    "## Full method for classifying cells as oscillatory based on synthetic OU cells (as in article)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3bb7a3b",
   "metadata": {},
   "source": [
    "For the full method we will use synthetic, non-oscillating cells to create a synthetic LLR_list. This will indicate the possible distribution of LLR scores that are generated by a non-periodic process.\n",
    "\n",
    "We use the fitted parameters of the OU model for each cell to create a dataset of non-oscillating OU simulated cells with the same time length as the data. We then calculate the LLR of the OUosc vs OU model for each synthetic cell and store it in LLR_list_synth. This list of LLRs from the synthetic cells will be used to calculate the q-values during the final step of the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7980bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "repeats = 10  # this controls the number of synthetic OU cells simulated for each observed cell\n",
    "\n",
    "LLR_list_synth = []\n",
    "\n",
    "for cell in range(N):\n",
    "    print(cell)\n",
    "\n",
    "    X = time[: y_length[cell]]\n",
    "    noise = noise_list[cell]\n",
    "\n",
    "    k_se = detrend_param_list[cell]\n",
    "    k_ou = OU_param_list[cell]\n",
    "    k_white = gpflow.kernels.White(variance=noise**2)\n",
    "\n",
    "    k_synth = k_se + k_ou + k_white\n",
    "\n",
    "    for repeat in range(repeats):\n",
    "        y_synth = np.random.multivariate_normal(np.zeros(len(X)), k_synth(X)).reshape(\n",
    "            -1, 1\n",
    "        )\n",
    "        k_trend, mean_trend, var_trend, Y_detrended = detrend_cell(X, y_synth, 7.0)\n",
    "        LLR, BICdiff, k_ou, k_ou_osc, period = fit_models(X, Y_detrended, noise, 10)\n",
    "        LLR_list_synth.append(LLR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4ba025",
   "metadata": {},
   "source": [
    "We can plot a side-by-side comparison of the LLR scores from the data and the synthetic cells. \n",
    "\n",
    "The list of LLR scores generated from the synthetic non-oscillatory cells shows that sometimes even simulated non-oscillatory cells will occasionally have quite a high LLR score, just by chance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cecea681",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20 / 2.54, 10 / 2.54))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(LLR_list, bins=np.linspace(0, 40, 40))\n",
    "plt.xlabel(\"LLR\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"LLRs of experimental cells\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(LLR_list_synth, bins=np.linspace(0, 40, 40))\n",
    "plt.xlabel(\"LLR\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"LLRs of synthetic non-oscillatory OU cells\")\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade23570",
   "metadata": {},
   "source": [
    "In the final step, we will use these two distributions to calculate a q-value for the presence of oscillations in each experimental cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe2b54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "LLR_array = np.array(LLR_list)\n",
    "LLR_synth_array = np.array(LLR_list_synth)\n",
    "\n",
    "# LLRs can be tiny and just negative - this just sets them to zero\n",
    "LLR_array[LLR_array < 0] = 0\n",
    "LLR_synth_array[LLR_synth_array < 0] = 0\n",
    "\n",
    "LLR_combined = np.concatenate((LLR_array, LLR_synth_array), 0)\n",
    "\n",
    "upper = np.max(LLR_combined)\n",
    "lower1 = np.min(LLR_combined)\n",
    "lower = upper - 0.9 * (upper - lower1)\n",
    "grid = np.linspace(lower, upper, 20)\n",
    "\n",
    "piest = np.zeros_like(grid)\n",
    "\n",
    "for i, cutoff in enumerate(grid):\n",
    "    num = sum(LLR_array < cutoff) / len(LLR_array)\n",
    "    denom = sum(LLR_synth_array < cutoff) / len(LLR_synth_array)\n",
    "    piest[i] = num / denom\n",
    "\n",
    "xx = np.linspace(lower, upper, 100)\n",
    "from scipy.interpolate import CubicSpline\n",
    "\n",
    "cs = CubicSpline(grid, piest)\n",
    "yy = cs(xx)\n",
    "\n",
    "piGUESS1 = yy[0]\n",
    "\n",
    "I = np.argsort(LLR_array)\n",
    "\n",
    "LLR_array_sorted = LLR_array[I]\n",
    "\n",
    "q1 = np.zeros_like(LLR_array_sorted)\n",
    "\n",
    "for i, thresh in enumerate(LLR_array_sorted):\n",
    "    q1[i] = (\n",
    "        piGUESS1\n",
    "        * (sum(LLR_synth_array >= thresh) / len(LLR_synth_array))\n",
    "        / (sum(LLR_array_sorted >= thresh) / len(LLR_array_sorted))\n",
    "    )\n",
    "\n",
    "q_vals = q1[np.argsort(I)]\n",
    "osc_filt = q_vals < 0.05\n",
    "\n",
    "print(\n",
    "    \"Number of cells counted as oscillatory (full method): {0}/{1}\".format(\n",
    "        sum(osc_filt), len(osc_filt)\n",
    "    )\n",
    ")\n",
    "\n",
    "period_array = np.array(period_list)\n",
    "plt.hist(period_array[osc_filt], bins=np.linspace(0, 10, 20))\n",
    "plt.title(\"Periods of passing cells\")\n",
    "plt.xlabel(\"Period (hours)\")\n",
    "plt.ylabel(\"Frequency\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63216013",
   "metadata": {},
   "source": [
    "The variable osc_filt is a boolean array that outputs \"True\" for each cell when its associated q-value is below the stated threshold (here we use 0.05). \n",
    "\n",
    "The final figure shows the period of each cell that passes the oscillatory test."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
